{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe6df8dd-5fbf-456b-b3f3-b043db9ea979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\rahma\\mr\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\rahma\\mr\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rahma\\mr\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rahma\\mr\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rahma\\mr\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rahma\\mr\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442a4f42-455a-4b61-bd96-f5245efa9475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the path to the zipped folder on your Desktop\n",
    "\n",
    "zip_file_path = r'C:\\Users\\rahma\\Desktop\\Assignment2.zip'\n",
    "extracted_folder = 'extracted_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf3d4e5-74af-45cb-9556-8029b07e5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the files from the zip folder\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de4c7907-139d-4bd4-bcd8-f397ebac7b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the path to the output .txt file on the Desktop\n",
    "\n",
    "output_file = r'C:\\Users\\rahma\\Desktop\\output_texts.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957e131f-32d9-4ec3-8002-b5b05e78e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_count = 0  # Count how many files we're processing\n",
    "unique_files = set()  # Set to track unique CSV file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb7d4ac-f391-4f5b-9eff-9cc5f4171936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: extracted_files\\CSV1.csv\n",
      "Columns in CSV1.csv: ['Unnamed: 0', 'HADM_ID', 'SHORT-TEXT', 'ICD9_CODE', 'ICD9', 'Label']\n",
      "Normalized columns in CSV1.csv: ['unnamed: 0', 'hadm_id', 'short-text', 'icd9_code', 'icd9', 'label']\n",
      "Found 'short-text' column in CSV1.csv\n",
      "\n",
      "Processing file: extracted_files\\CSV2.csv\n",
      "Columns in CSV2.csv: ['Unnamed: 0', 'HADM_ID', 'TEXT', 'LABLE', 'entites', 'group']\n",
      "Normalized columns in CSV2.csv: ['unnamed: 0', 'hadm_id', 'text', 'lable', 'entites', 'group']\n",
      "Found 'text' column in CSV2.csv\n",
      "\n",
      "Processing file: extracted_files\\CSV3.csv\n",
      "Columns in CSV3.csv: ['HADM_ID', 'TEXT', 'ICD9_CODE', 'Label']\n",
      "Normalized columns in CSV3.csv: ['hadm_id', 'text', 'icd9_code', 'label']\n",
      "Found 'text' column in CSV3.csv\n",
      "\n",
      "Processing file: extracted_files\\CSV4.csv\n",
      "Columns in CSV4.csv: ['HADM_ID', 'TEXT', 'LABLE']\n",
      "Normalized columns in CSV4.csv: ['hadm_id', 'text', 'lable']\n",
      "Found 'text' column in CSV4.csv\n"
     ]
    }
   ],
   "source": [
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    \n",
    "    #Loop through the extracted folder to find CSV files\n",
    "    for root, dirs, files in os.walk(extracted_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "               \n",
    "                if file in unique_files:\n",
    "                    continue  # Skip duplicate files\n",
    "\n",
    "                unique_files.add(file)  \n",
    "                file_count += 1\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"\\nProcessing file: {file_path}\")  # Debug: Print the file being processed\n",
    "                \n",
    "                try:\n",
    "                    #Read the CSV file\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    \n",
    "                    #Print the column names as they are read\n",
    "                    print(f\"Columns in {file}: {df.columns.tolist()}\")\n",
    "\n",
    "                    #Normalize column names\n",
    "                    df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "                    #Print the normalized column names to verify\n",
    "                    print(f\"Normalized columns in {file}: {df.columns.tolist()}\")\n",
    "\n",
    "                    #Identify and extract the 'text' or 'short-text' column\n",
    "                    if 'text' in df.columns:\n",
    "                        print(f\"Found 'text' column in {file}\")\n",
    "                        \n",
    "                        texts = df['text'].dropna().tolist()  # Drop NaN values and convert the column to a list\n",
    "\n",
    "                    elif 'short-text' in df.columns:\n",
    "                        print(f\"Found 'short-text' column in {file}\")\n",
    "                        texts = df['short-text'].dropna().tolist()\n",
    "                    else:\n",
    "                        print(f\"Neither 'text' nor 'short-text' column found in {file}\")\n",
    "                        continue\n",
    "                    \n",
    "                    #Write each text entry to the output .txt file\n",
    "                    for text in texts:\n",
    "                        outfile.write(text + '\\n\\n')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7ad9ec-c7b0-4bc1-b470-8c7fd25fbbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 4 unique CSV files.\n",
      "All texts have been written to C:\\Users\\rahma\\Desktop\\output_texts.txt\n"
     ]
    }
   ],
   "source": [
    "#Print the number of processed files\n",
    "print(f\"\\nProcessed {file_count} unique CSV files.\")\n",
    "print(f\"All texts have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f72ff-3508-4582-b159-81acc13d5f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
